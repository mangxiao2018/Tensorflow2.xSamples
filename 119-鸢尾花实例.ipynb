{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鸢尾花实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、引入相关组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
    " \n",
    "# 导入所需模块\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、导入鸢尾花数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据，分别为输入特征和标签\n",
    "x_data = datasets.load_iris().data\n",
    "y_data = datasets.load_iris().target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、数据加工处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
    "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
    "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
    "np.random.shuffle(x_data)\n",
    "np.random.seed(116)\n",
    "np.random.shuffle(y_data)\n",
    "tf.random.set_seed(116)\n",
    "\n",
    "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
    "x_train = x_data[:-30]\n",
    "y_train = y_data[:-30]\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]\n",
    "\n",
    "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "x_test = tf.cast(x_test, tf.float32)\n",
    "\n",
    "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
    "# 用tf.Variable()标记参数可训练\n",
    "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
    "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
    "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.2821310982108116\n",
      "Epoch 1, loss: 0.25459614023566246\n",
      "Epoch 2, loss: 0.22570250183343887\n",
      "Epoch 3, loss: 0.21028400212526321\n",
      "Epoch 4, loss: 0.19942265003919601\n",
      "Epoch 5, loss: 0.18873638287186623\n",
      "Epoch 6, loss: 0.17851299419999123\n",
      "Epoch 7, loss: 0.16922875493764877\n",
      "Epoch 8, loss: 0.16107673197984695\n",
      "Epoch 9, loss: 0.15404684096574783\n",
      "Epoch 10, loss: 0.14802725985646248\n",
      "Epoch 11, loss: 0.14287303388118744\n",
      "Epoch 12, loss: 0.1384414155036211\n",
      "Epoch 13, loss: 0.13460607267916203\n",
      "Epoch 14, loss: 0.1312607266008854\n",
      "Epoch 15, loss: 0.12831821851432323\n",
      "Epoch 16, loss: 0.12570794858038425\n",
      "Epoch 17, loss: 0.12337299063801765\n",
      "Epoch 18, loss: 0.12126746959984303\n",
      "Epoch 19, loss: 0.11935433000326157\n",
      "Epoch 20, loss: 0.11760355532169342\n",
      "Epoch 21, loss: 0.11599067784845829\n",
      "Epoch 22, loss: 0.11449568346142769\n",
      "Epoch 23, loss: 0.11310208030045033\n",
      "Epoch 24, loss: 0.11179621517658234\n",
      "Epoch 25, loss: 0.11056671850383282\n",
      "Epoch 26, loss: 0.1094040796160698\n",
      "Epoch 27, loss: 0.10830028168857098\n",
      "Epoch 28, loss: 0.10724855586886406\n",
      "Epoch 29, loss: 0.10624313727021217\n",
      "Epoch 30, loss: 0.1052791029214859\n",
      "Epoch 31, loss: 0.10435222089290619\n",
      "Epoch 32, loss: 0.10345886647701263\n",
      "Epoch 33, loss: 0.10259587690234184\n",
      "Epoch 34, loss: 0.10176053084433079\n",
      "Epoch 35, loss: 0.10095042362809181\n",
      "Epoch 36, loss: 0.10016347281634808\n",
      "Epoch 37, loss: 0.09939785301685333\n",
      "Epoch 38, loss: 0.098651934415102\n",
      "Epoch 39, loss: 0.09792428836226463\n",
      "Epoch 40, loss: 0.09721364639699459\n",
      "Epoch 41, loss: 0.09651889279484749\n",
      "Epoch 42, loss: 0.09583901055157185\n",
      "Epoch 43, loss: 0.09517310746014118\n",
      "Epoch 44, loss: 0.09452036395668983\n",
      "Epoch 45, loss: 0.0938800685107708\n",
      "Epoch 46, loss: 0.09325156174600124\n",
      "Epoch 47, loss: 0.09263424947857857\n",
      "Epoch 48, loss: 0.09202760085463524\n",
      "Epoch 49, loss: 0.09143111668527126\n",
      "Epoch 50, loss: 0.09084436297416687\n",
      "Epoch 51, loss: 0.09026693738996983\n",
      "Epoch 52, loss: 0.08969846740365028\n",
      "Epoch 53, loss: 0.08913861028850079\n",
      "Epoch 54, loss: 0.08858705312013626\n",
      "Epoch 55, loss: 0.08804351277649403\n",
      "Epoch 56, loss: 0.08750772476196289\n",
      "Epoch 57, loss: 0.08697944693267345\n",
      "Epoch 58, loss: 0.08645843341946602\n",
      "Epoch 59, loss: 0.08594449236989021\n",
      "Epoch 60, loss: 0.08543741516768932\n",
      "Epoch 61, loss: 0.08493702113628387\n",
      "Epoch 62, loss: 0.08444313704967499\n",
      "Epoch 63, loss: 0.08395560085773468\n",
      "Epoch 64, loss: 0.08347426354885101\n",
      "Epoch 65, loss: 0.08299897983670235\n",
      "Epoch 66, loss: 0.08252961002290249\n",
      "Epoch 67, loss: 0.08206603676080704\n",
      "Epoch 68, loss: 0.0816081278026104\n",
      "Epoch 69, loss: 0.08115577697753906\n",
      "Epoch 70, loss: 0.08070887438952923\n",
      "Epoch 71, loss: 0.08026730641722679\n",
      "Epoch 72, loss: 0.07983098179101944\n",
      "Epoch 73, loss: 0.07939981482923031\n",
      "Epoch 74, loss: 0.07897369377315044\n",
      "Epoch 75, loss: 0.07855254411697388\n",
      "Epoch 76, loss: 0.07813627645373344\n",
      "Epoch 77, loss: 0.07772481068968773\n",
      "Epoch 78, loss: 0.07731806486845016\n",
      "Epoch 79, loss: 0.07691597566008568\n",
      "Epoch 80, loss: 0.07651845179498196\n",
      "Epoch 81, loss: 0.07612544111907482\n",
      "Epoch 82, loss: 0.07573685608804226\n",
      "Epoch 83, loss: 0.07535265013575554\n",
      "Epoch 84, loss: 0.07497275061905384\n",
      "Epoch 85, loss: 0.07459708210080862\n",
      "Epoch 86, loss: 0.07422559335827827\n",
      "Epoch 87, loss: 0.07385822758078575\n",
      "Epoch 88, loss: 0.07349492330104113\n",
      "Epoch 89, loss: 0.0731356181204319\n",
      "Epoch 90, loss: 0.0727802598848939\n",
      "Epoch 91, loss: 0.07242879830300808\n",
      "Epoch 92, loss: 0.07208118122071028\n",
      "Epoch 93, loss: 0.07173734251409769\n",
      "Epoch 94, loss: 0.07139723561704159\n",
      "Epoch 95, loss: 0.07106082048267126\n",
      "Epoch 96, loss: 0.07072803843766451\n",
      "Epoch 97, loss: 0.07039883732795715\n",
      "Epoch 98, loss: 0.07007318176329136\n",
      "Epoch 99, loss: 0.0697510102763772\n",
      "Epoch 100, loss: 0.06943229492753744\n",
      "Epoch 101, loss: 0.06911696959286928\n",
      "Epoch 102, loss: 0.06880500260740519\n",
      "Epoch 103, loss: 0.068496348336339\n",
      "Epoch 104, loss: 0.06819095741957426\n",
      "Epoch 105, loss: 0.06788879353553057\n",
      "Epoch 106, loss: 0.06758981756865978\n",
      "Epoch 107, loss: 0.0672939782962203\n",
      "Epoch 108, loss: 0.06700124125927687\n",
      "Epoch 109, loss: 0.06671155989170074\n",
      "Epoch 110, loss: 0.06642490718513727\n",
      "Epoch 111, loss: 0.06614123564213514\n",
      "Epoch 112, loss: 0.06586050800979137\n",
      "Epoch 113, loss: 0.06558268237859011\n",
      "Epoch 114, loss: 0.06530772428959608\n",
      "Epoch 115, loss: 0.06503560300916433\n",
      "Epoch 116, loss: 0.06476627010852098\n",
      "Epoch 117, loss: 0.06449970323592424\n",
      "Epoch 118, loss: 0.06423585396260023\n",
      "Epoch 119, loss: 0.06397469528019428\n",
      "Epoch 120, loss: 0.06371619179844856\n",
      "Epoch 121, loss: 0.06346031185239553\n",
      "Epoch 122, loss: 0.06320700887590647\n",
      "Epoch 123, loss: 0.06295627169311047\n",
      "Epoch 124, loss: 0.06270804442465305\n",
      "Epoch 125, loss: 0.062462314032018185\n",
      "Epoch 126, loss: 0.062219033017754555\n",
      "Epoch 127, loss: 0.061978185549378395\n",
      "Epoch 128, loss: 0.06173973437398672\n",
      "Epoch 129, loss: 0.06150364130735397\n",
      "Epoch 130, loss: 0.06126988586038351\n",
      "Epoch 131, loss: 0.06103843078017235\n",
      "Epoch 132, loss: 0.060809263959527016\n",
      "Epoch 133, loss: 0.06058233231306076\n",
      "Epoch 134, loss: 0.06035762373358011\n",
      "Epoch 135, loss: 0.06013510562479496\n",
      "Epoch 136, loss: 0.05991474352777004\n",
      "Epoch 137, loss: 0.05969652719795704\n",
      "Epoch 138, loss: 0.05948041472584009\n",
      "Epoch 139, loss: 0.059266386553645134\n",
      "Epoch 140, loss: 0.059054408222436905\n",
      "Epoch 141, loss: 0.058844465762376785\n",
      "Epoch 142, loss: 0.05863652750849724\n",
      "Epoch 143, loss: 0.058430563658475876\n",
      "Epoch 144, loss: 0.058226559311151505\n",
      "Epoch 145, loss: 0.05802448187023401\n",
      "Epoch 146, loss: 0.05782431084662676\n",
      "Epoch 147, loss: 0.0576260257512331\n",
      "Epoch 148, loss: 0.05742959305644035\n",
      "Epoch 149, loss: 0.057234992273151875\n",
      "Epoch 150, loss: 0.05704221595078707\n",
      "Epoch 151, loss: 0.05685121938586235\n",
      "Epoch 152, loss: 0.05666199326515198\n",
      "Epoch 153, loss: 0.05647451523691416\n",
      "Epoch 154, loss: 0.0562887629494071\n",
      "Epoch 155, loss: 0.05610471125692129\n",
      "Epoch 156, loss: 0.05592234432697296\n",
      "Epoch 157, loss: 0.0557416332885623\n",
      "Epoch 158, loss: 0.05556256324052811\n",
      "Epoch 159, loss: 0.05538512021303177\n",
      "Epoch 160, loss: 0.05520927160978317\n",
      "Epoch 161, loss: 0.0550350034609437\n",
      "Epoch 162, loss: 0.054862307384610176\n",
      "Epoch 163, loss: 0.05469114426523447\n",
      "Epoch 164, loss: 0.05452151037752628\n",
      "Epoch 165, loss: 0.05435337871313095\n",
      "Epoch 166, loss: 0.05418673437088728\n",
      "Epoch 167, loss: 0.054021554067730904\n",
      "Epoch 168, loss: 0.053857832215726376\n",
      "Epoch 169, loss: 0.05369554739445448\n",
      "Epoch 170, loss: 0.05353467632085085\n",
      "Epoch 171, loss: 0.05337520316243172\n",
      "Epoch 172, loss: 0.05321711581200361\n",
      "Epoch 173, loss: 0.053060390055179596\n",
      "Epoch 174, loss: 0.05290501844137907\n",
      "Epoch 175, loss: 0.05275098513811827\n",
      "Epoch 176, loss: 0.0525982566177845\n",
      "Epoch 177, loss: 0.05244683939963579\n",
      "Epoch 178, loss: 0.05229670740664005\n",
      "Epoch 179, loss: 0.05214785039424896\n",
      "Epoch 180, loss: 0.052000246942043304\n",
      "Epoch 181, loss: 0.05185388680547476\n",
      "Epoch 182, loss: 0.05170875135809183\n",
      "Epoch 183, loss: 0.0515648303553462\n",
      "Epoch 184, loss: 0.0514221116900444\n",
      "Epoch 185, loss: 0.05128058046102524\n",
      "Epoch 186, loss: 0.05114021524786949\n",
      "Epoch 187, loss: 0.051001012325286865\n",
      "Epoch 188, loss: 0.0508629409596324\n",
      "Epoch 189, loss: 0.05072600767016411\n",
      "Epoch 190, loss: 0.05059019848704338\n",
      "Epoch 191, loss: 0.05045548640191555\n",
      "Epoch 192, loss: 0.050321875140070915\n",
      "Epoch 193, loss: 0.05018933489918709\n",
      "Epoch 194, loss: 0.05005786381661892\n",
      "Epoch 195, loss: 0.04992745537310839\n",
      "Epoch 196, loss: 0.04979807883501053\n",
      "Epoch 197, loss: 0.04966974165290594\n",
      "Epoch 198, loss: 0.04954242426902056\n",
      "Epoch 199, loss: 0.04941611457616091\n",
      "Epoch 200, loss: 0.049290805123746395\n",
      "Epoch 201, loss: 0.049166472628712654\n",
      "Epoch 202, loss: 0.04904312454164028\n",
      "Epoch 203, loss: 0.04892073106020689\n",
      "Epoch 204, loss: 0.04879929404705763\n",
      "Epoch 205, loss: 0.04867880046367645\n",
      "Epoch 206, loss: 0.04855923913419247\n",
      "Epoch 207, loss: 0.048440598882734776\n",
      "Epoch 208, loss: 0.04832286946475506\n",
      "Epoch 209, loss: 0.04820604622364044\n",
      "Epoch 210, loss: 0.04809010960161686\n",
      "Epoch 211, loss: 0.04797505959868431\n",
      "Epoch 212, loss: 0.04786087851971388\n",
      "Epoch 213, loss: 0.047747560776770115\n",
      "Epoch 214, loss: 0.04763508960604668\n",
      "Epoch 215, loss: 0.04752346687018871\n",
      "Epoch 216, loss: 0.0474126823246479\n",
      "Epoch 217, loss: 0.04730272572487593\n",
      "Epoch 218, loss: 0.04719358030706644\n",
      "Epoch 219, loss: 0.04708524979650974\n",
      "Epoch 220, loss: 0.046977708116173744\n",
      "Epoch 221, loss: 0.046870965510606766\n",
      "Epoch 222, loss: 0.04676500242203474\n",
      "Epoch 223, loss: 0.046659816056489944\n",
      "Epoch 224, loss: 0.046555391512811184\n",
      "Epoch 225, loss: 0.04645173158496618\n",
      "Epoch 226, loss: 0.046348825097084045\n",
      "Epoch 227, loss: 0.04624664504081011\n",
      "Epoch 228, loss: 0.046145214699208736\n",
      "Epoch 229, loss: 0.04604450333863497\n",
      "Epoch 230, loss: 0.04594451282173395\n",
      "Epoch 231, loss: 0.045845234766602516\n",
      "Epoch 232, loss: 0.04574666079133749\n",
      "Epoch 233, loss: 0.04564878437668085\n",
      "Epoch 234, loss: 0.04555159714072943\n",
      "Epoch 235, loss: 0.04545509163290262\n",
      "Epoch 236, loss: 0.045359269715845585\n",
      "Epoch 237, loss: 0.04526410344988108\n",
      "Epoch 238, loss: 0.04516960680484772\n",
      "Epoch 239, loss: 0.04507576581090689\n",
      "Epoch 240, loss: 0.044982570223510265\n",
      "Epoch 241, loss: 0.04489001724869013\n",
      "Epoch 242, loss: 0.04479810781776905\n",
      "Epoch 243, loss: 0.04470681864768267\n",
      "Epoch 244, loss: 0.04461614973843098\n",
      "Epoch 245, loss: 0.04452611040323973\n",
      "Epoch 246, loss: 0.04443667363375425\n",
      "Epoch 247, loss: 0.044347839429974556\n",
      "Epoch 248, loss: 0.04425961058586836\n",
      "Epoch 249, loss: 0.04417197220027447\n",
      "Epoch 250, loss: 0.044084908440709114\n",
      "Epoch 251, loss: 0.043998440727591515\n",
      "Epoch 252, loss: 0.04391253925859928\n",
      "Epoch 253, loss: 0.043827205896377563\n",
      "Epoch 254, loss: 0.04374244436621666\n",
      "Epoch 255, loss: 0.04365824069827795\n",
      "Epoch 256, loss: 0.04357459116727114\n",
      "Epoch 257, loss: 0.043491488322615623\n",
      "Epoch 258, loss: 0.043408920988440514\n",
      "Epoch 259, loss: 0.043326896615326405\n",
      "Epoch 260, loss: 0.04324540589004755\n",
      "Epoch 261, loss: 0.043164435774087906\n",
      "Epoch 262, loss: 0.04308399651199579\n",
      "Epoch 263, loss: 0.043004062958061695\n",
      "Epoch 264, loss: 0.04292465187609196\n",
      "Epoch 265, loss: 0.04284573998302221\n",
      "Epoch 266, loss: 0.04276733938604593\n",
      "Epoch 267, loss: 0.042689427733421326\n",
      "Epoch 268, loss: 0.042612009681761265\n",
      "Epoch 269, loss: 0.042535084299743176\n",
      "Epoch 270, loss: 0.04245864413678646\n",
      "Epoch 271, loss: 0.0423826826736331\n",
      "Epoch 272, loss: 0.042307195253670216\n",
      "Epoch 273, loss: 0.04223217722028494\n",
      "Epoch 274, loss: 0.0421576201915741\n",
      "Epoch 275, loss: 0.042083533480763435\n",
      "Epoch 276, loss: 0.04200989939272404\n",
      "Epoch 277, loss: 0.041936714202165604\n",
      "Epoch 278, loss: 0.041863986290991306\n",
      "Epoch 279, loss: 0.04179169982671738\n",
      "Epoch 280, loss: 0.041719854809343815\n",
      "Epoch 281, loss: 0.041648441925644875\n",
      "Epoch 282, loss: 0.04157746955752373\n",
      "Epoch 283, loss: 0.04150692094117403\n",
      "Epoch 284, loss: 0.04143680352717638\n",
      "Epoch 285, loss: 0.04136709962040186\n",
      "Epoch 286, loss: 0.04129782039672136\n",
      "Epoch 287, loss: 0.04122895374894142\n",
      "Epoch 288, loss: 0.04116049408912659\n",
      "Epoch 289, loss: 0.04109244793653488\n",
      "Epoch 290, loss: 0.04102479945868254\n",
      "Epoch 291, loss: 0.04095755238085985\n",
      "Epoch 292, loss: 0.040890694595873356\n",
      "Epoch 293, loss: 0.040824233554303646\n",
      "Epoch 294, loss: 0.040758166462183\n",
      "Epoch 295, loss: 0.040692479349672794\n",
      "Epoch 296, loss: 0.04062717128545046\n",
      "Epoch 297, loss: 0.040562248788774014\n",
      "Epoch 298, loss: 0.04049769788980484\n",
      "Epoch 299, loss: 0.04043351951986551\n",
      "Epoch 300, loss: 0.04036970995366573\n",
      "Epoch 301, loss: 0.040306271985173225\n",
      "Epoch 302, loss: 0.04024319350719452\n",
      "Epoch 303, loss: 0.04018046986311674\n",
      "Epoch 304, loss: 0.040118103846907616\n",
      "Epoch 305, loss: 0.04005609406158328\n",
      "Epoch 306, loss: 0.03999443957582116\n",
      "Epoch 307, loss: 0.03993312222883105\n",
      "Epoch 308, loss: 0.039872155059129\n",
      "Epoch 309, loss: 0.03981153108179569\n",
      "Epoch 310, loss: 0.03975124144926667\n",
      "Epoch 311, loss: 0.03969129454344511\n",
      "Epoch 312, loss: 0.03963167825713754\n",
      "Epoch 313, loss: 0.039572385139763355\n",
      "Epoch 314, loss: 0.0395134249702096\n",
      "Epoch 315, loss: 0.039454787503927946\n",
      "Epoch 316, loss: 0.039396482054144144\n",
      "Epoch 317, loss: 0.03933848813176155\n",
      "Epoch 318, loss: 0.03928081039339304\n",
      "Epoch 319, loss: 0.039223446510732174\n",
      "Epoch 320, loss: 0.039166401606053114\n",
      "Epoch 321, loss: 0.039109662640839815\n",
      "Epoch 322, loss: 0.03905322263017297\n",
      "Epoch 323, loss: 0.03899709461256862\n",
      "Epoch 324, loss: 0.03894126648083329\n",
      "Epoch 325, loss: 0.038885737769305706\n",
      "Epoch 326, loss: 0.03883049916476011\n",
      "Epoch 327, loss: 0.03877555998042226\n",
      "Epoch 328, loss: 0.03872091369703412\n",
      "Epoch 329, loss: 0.038666556123644114\n",
      "Epoch 330, loss: 0.0386124849319458\n",
      "Epoch 331, loss: 0.038558701518923044\n",
      "Epoch 332, loss: 0.03850520169362426\n",
      "Epoch 333, loss: 0.03845197660848498\n",
      "Epoch 334, loss: 0.03839903511106968\n",
      "Epoch 335, loss: 0.03834636742249131\n",
      "Epoch 336, loss: 0.03829397866502404\n",
      "Epoch 337, loss: 0.038241852074861526\n",
      "Epoch 338, loss: 0.03819000208750367\n",
      "Epoch 339, loss: 0.03813841659575701\n",
      "Epoch 340, loss: 0.038087102584540844\n",
      "Epoch 341, loss: 0.03803604608401656\n",
      "Epoch 342, loss: 0.037985255010426044\n",
      "Epoch 343, loss: 0.0379347144626081\n",
      "Epoch 344, loss: 0.03788443887606263\n",
      "Epoch 345, loss: 0.037834418937563896\n",
      "Epoch 346, loss: 0.03778465045616031\n",
      "Epoch 347, loss: 0.03773513110354543\n",
      "Epoch 348, loss: 0.03768586413934827\n",
      "Epoch 349, loss: 0.03763684118166566\n",
      "Epoch 350, loss: 0.037588071543723345\n",
      "Epoch 351, loss: 0.037539539858698845\n",
      "Epoch 352, loss: 0.03749124659225345\n",
      "Epoch 353, loss: 0.03744320431724191\n",
      "Epoch 354, loss: 0.03739539487287402\n",
      "Epoch 355, loss: 0.037347821053117514\n",
      "Epoch 356, loss: 0.037300472147762775\n",
      "Epoch 357, loss: 0.03725337469950318\n",
      "Epoch 358, loss: 0.03720649937167764\n",
      "Epoch 359, loss: 0.037159846629947424\n",
      "Epoch 360, loss: 0.03711343090981245\n",
      "Epoch 361, loss: 0.03706724522635341\n",
      "Epoch 362, loss: 0.03702127141878009\n",
      "Epoch 363, loss: 0.036975531373173\n",
      "Epoch 364, loss: 0.036930006463080645\n",
      "Epoch 365, loss: 0.036884702276438475\n",
      "Epoch 366, loss: 0.03683961182832718\n",
      "Epoch 367, loss: 0.036794747691601515\n",
      "Epoch 368, loss: 0.03675009263679385\n",
      "Epoch 369, loss: 0.03670565178617835\n",
      "Epoch 370, loss: 0.03666142327710986\n",
      "Epoch 371, loss: 0.036617396865040064\n",
      "Epoch 372, loss: 0.03657358651980758\n",
      "Epoch 373, loss: 0.03652997827157378\n",
      "Epoch 374, loss: 0.03648658422753215\n",
      "Epoch 375, loss: 0.03644339134916663\n",
      "Epoch 376, loss: 0.03640039125457406\n",
      "Epoch 377, loss: 0.03635760257020593\n",
      "Epoch 378, loss: 0.0363150117918849\n",
      "Epoch 379, loss: 0.03627262031659484\n",
      "Epoch 380, loss: 0.036230423022061586\n",
      "Epoch 381, loss: 0.03618842549622059\n",
      "Epoch 382, loss: 0.03614661982282996\n",
      "Epoch 383, loss: 0.036105002742260695\n",
      "Epoch 384, loss: 0.03606357332319021\n",
      "Epoch 385, loss: 0.036022343672811985\n",
      "Epoch 386, loss: 0.03598130075260997\n",
      "Epoch 387, loss: 0.0359404431656003\n",
      "Epoch 388, loss: 0.035899775102734566\n",
      "Epoch 389, loss: 0.03585928911343217\n",
      "Epoch 390, loss: 0.035818991251289845\n",
      "Epoch 391, loss: 0.03577886475250125\n",
      "Epoch 392, loss: 0.035738930106163025\n",
      "Epoch 393, loss: 0.035699169617146254\n",
      "Epoch 394, loss: 0.03565958747640252\n",
      "Epoch 395, loss: 0.0356201883405447\n",
      "Epoch 396, loss: 0.03558096336200833\n",
      "Epoch 397, loss: 0.035541911609470844\n",
      "Epoch 398, loss: 0.035503033082932234\n",
      "Epoch 399, loss: 0.03546432685106993\n",
      "Epoch 400, loss: 0.03542578825727105\n",
      "Epoch 401, loss: 0.03538742894306779\n",
      "Epoch 402, loss: 0.03534923028200865\n",
      "Epoch 403, loss: 0.03531120624393225\n",
      "Epoch 404, loss: 0.03527334099635482\n",
      "Epoch 405, loss: 0.035235646180808544\n",
      "Epoch 406, loss: 0.035198114812374115\n",
      "Epoch 407, loss: 0.03516074409708381\n",
      "Epoch 408, loss: 0.03512354753911495\n",
      "Epoch 409, loss: 0.035086496733129025\n",
      "Epoch 410, loss: 0.03504961961880326\n",
      "Epoch 411, loss: 0.03501288779079914\n",
      "Epoch 412, loss: 0.03497632406651974\n",
      "Epoch 413, loss: 0.034939910750836134\n",
      "Epoch 414, loss: 0.034903660882264376\n",
      "Epoch 415, loss: 0.03486755723133683\n",
      "Epoch 416, loss: 0.034831615164875984\n",
      "Epoch 417, loss: 0.03479582257568836\n",
      "Epoch 418, loss: 0.034760179463773966\n",
      "Epoch 419, loss: 0.03472469002008438\n",
      "Epoch 420, loss: 0.034689351450651884\n",
      "Epoch 421, loss: 0.03465416468679905\n",
      "Epoch 422, loss: 0.03461912088096142\n",
      "Epoch 423, loss: 0.034584226086735725\n",
      "Epoch 424, loss: 0.0345494719222188\n",
      "Epoch 425, loss: 0.03451487235724926\n",
      "Epoch 426, loss: 0.034480408765375614\n",
      "Epoch 427, loss: 0.03444609651342034\n",
      "Epoch 428, loss: 0.03441191930323839\n",
      "Epoch 429, loss: 0.034377888310700655\n",
      "Epoch 430, loss: 0.0343439974822104\n",
      "Epoch 431, loss: 0.03431024495512247\n",
      "Epoch 432, loss: 0.034276632592082024\n",
      "Epoch 433, loss: 0.03424314921721816\n",
      "Epoch 434, loss: 0.034209814853966236\n",
      "Epoch 435, loss: 0.034176611341536045\n",
      "Epoch 436, loss: 0.03414354659616947\n",
      "Epoch 437, loss: 0.034110613632947206\n",
      "Epoch 438, loss: 0.03407781524583697\n",
      "Epoch 439, loss: 0.03404514491558075\n",
      "Epoch 440, loss: 0.03401261428371072\n",
      "Epoch 441, loss: 0.03398020705208182\n",
      "Epoch 442, loss: 0.03394793579354882\n",
      "Epoch 443, loss: 0.03391578933224082\n",
      "Epoch 444, loss: 0.033883774653077126\n",
      "Epoch 445, loss: 0.03385189222171903\n",
      "Epoch 446, loss: 0.03382013039663434\n",
      "Epoch 447, loss: 0.033788496162742376\n",
      "Epoch 448, loss: 0.033756992779672146\n",
      "Epoch 449, loss: 0.03372560581192374\n",
      "Epoch 450, loss: 0.03369434829801321\n",
      "Epoch 451, loss: 0.03366321278735995\n",
      "Epoch 452, loss: 0.03363220160827041\n",
      "Epoch 453, loss: 0.03360130963847041\n",
      "Epoch 454, loss: 0.033570545725524426\n",
      "Epoch 455, loss: 0.03353988938033581\n",
      "Epoch 456, loss: 0.03350936621427536\n",
      "Epoch 457, loss: 0.03347895201295614\n",
      "Epoch 458, loss: 0.03344865795224905\n",
      "Epoch 459, loss: 0.033418478444218636\n",
      "Epoch 460, loss: 0.033388426061719656\n",
      "Epoch 461, loss: 0.033358484506607056\n",
      "Epoch 462, loss: 0.033328657038509846\n",
      "Epoch 463, loss: 0.033298940397799015\n",
      "Epoch 464, loss: 0.033269339706748724\n",
      "Epoch 465, loss: 0.03323985496535897\n",
      "Epoch 466, loss: 0.03321048337966204\n",
      "Epoch 467, loss: 0.03318122075870633\n",
      "Epoch 468, loss: 0.0331520764157176\n",
      "Epoch 469, loss: 0.033123028464615345\n",
      "Epoch 470, loss: 0.033094107173383236\n",
      "Epoch 471, loss: 0.033065286464989185\n",
      "Epoch 472, loss: 0.0330365770496428\n",
      "Epoch 473, loss: 0.03300797566771507\n",
      "Epoch 474, loss: 0.03297947999089956\n",
      "Epoch 475, loss: 0.03295109001919627\n",
      "Epoch 476, loss: 0.03292280342429876\n",
      "Epoch 477, loss: 0.03289463231340051\n",
      "Epoch 478, loss: 0.0328665585257113\n",
      "Epoch 479, loss: 0.03283859835937619\n",
      "Epoch 480, loss: 0.03281073085963726\n",
      "Epoch 481, loss: 0.03278297046199441\n",
      "Epoch 482, loss: 0.032755312509834766\n",
      "Epoch 483, loss: 0.03272775420919061\n",
      "Epoch 484, loss: 0.03270029416307807\n",
      "Epoch 485, loss: 0.032672947738319635\n",
      "Epoch 486, loss: 0.032645690720528364\n",
      "Epoch 487, loss: 0.03261853428557515\n",
      "Epoch 488, loss: 0.03259148681536317\n",
      "Epoch 489, loss: 0.03256453387439251\n",
      "Epoch 490, loss: 0.032537673600018024\n",
      "Epoch 491, loss: 0.03251091670244932\n",
      "Epoch 492, loss: 0.03248425014317036\n",
      "Epoch 493, loss: 0.0324576823040843\n",
      "Epoch 494, loss: 0.032431211322546005\n",
      "Epoch 495, loss: 0.03240483347326517\n",
      "Epoch 496, loss: 0.03237855713814497\n",
      "Epoch 497, loss: 0.03235236741602421\n",
      "Epoch 498, loss: 0.03232627175748348\n",
      "Epoch 499, loss: 0.0323002771474421\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1  # 学习率为0.1\n",
    "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
    "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
    "epoch = 500  # 循环500轮\n",
    "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和\n",
    "\n",
    "# 训练部分\n",
    "for epoch in range(epoch):  #数据集级别的循环，每个epoch循环一次数据集\n",
    "    for step, (x_train, y_train) in enumerate(train_db):  #batch级别的循环 ，每个step循环一个batch\n",
    "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
    "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
    "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
    "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
    "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
    "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
    "        # 计算loss对各个参数的梯度\n",
    "        grads = tape.gradient(loss, [w1, b1])\n",
    "\n",
    "        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad\n",
    "        w1.assign_sub(lr * grads[0])  # 参数w1自更新\n",
    "        b1.assign_sub(lr * grads[1])  # 参数b自更新\n",
    "\n",
    "    # 每个epoch，打印loss信息\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all/4))\n",
    "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
    "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # 测试部分\n",
    "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
    "    total_correct, total_number = 0, 0\n",
    "    for x_test, y_test in test_db:\n",
    "        # 使用更新后的参数进行预测\n",
    "        y = tf.matmul(x_test, w1) + b1\n",
    "        y = tf.nn.softmax(y)\n",
    "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
    "        # 将pred转换为y_test的数据类型\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
    "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        # 将每个batch的correct数加起来\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        # 将所有batch中的correct数加起来\n",
    "        total_correct += int(correct)\n",
    "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
    "        total_number += x_test.shape[0]\n",
    "    # 总的准确率等于total_correct/total_number\n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test_acc:\", acc)\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、图形化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制 loss 曲线\n",
    "plt.title('Loss Function Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Loss')  # y轴变量名称\n",
    "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
    "plt.legend()  # 画出曲线图标\n",
    "plt.show()  # 画出图像\n",
    "\n",
    "# 绘制 Accuracy 曲线\n",
    "plt.title('Acc Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Acc')  # y轴变量名称\n",
    "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
